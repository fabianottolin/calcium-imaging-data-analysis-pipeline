{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting functions_plots.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile functions_plots.py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import random\n",
    "from scipy.signal import find_peaks\n",
    "import pandas as pd\n",
    "from scipy.ndimage import binary_dilation, binary_fill_holes\n",
    "from configurations import *\n",
    "\n",
    "def random_individual_cell_histograms(deltaF_file, plot_number):\n",
    "    ## for individual cells, random sample of plot_number, (can also be set to randoms sample of size plot_number, i this case use code below to calculate plot number and then pass it to function) ##\n",
    "    ### ROI_number = len(np.load(file)) ## needs to be connected with plot number below if we always want to show fixed percentage of all possible histograms\n",
    "    ### plot_number = int(0.05*ROI_number) # plots random 5% of all cells\n",
    "    ### if plot_number <4: plot_number = 4\n",
    "    \n",
    "    array = np.load(rf\"{deltaF_file}\")\n",
    "    sample = random.sample(range(0, len(array)), plot_number)\n",
    "    for i in sample: ## alterantive i in range(len(array)) to plot all\n",
    "      plt.figure(figsize=(5,5))\n",
    "      plt.hist(array[i], density=True, bins=200)\n",
    "      plt.title(f'Histogram df/F fluorescence cell {i}')\n",
    "      plt.show()\n",
    "\n",
    "def deltaF_histogram_across_cells(deltaF_file):\n",
    "    array = np.load(rf\"{deltaF_file}\")\n",
    "    list = array.flatten()\n",
    "    list_cleaned = [x for x in list if not np.isnan(x)]\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.hist(list_cleaned, density=True, bins=200)\n",
    "    plt.title(f'Histogram df/F {deltaF_file[len(main_folder)+1:]}')\n",
    "    plt.show()\n",
    "\n",
    "def histogram_total_estimated_spikes(prediction_deltaF_file):\n",
    "    array = np.load(rf\"{prediction_deltaF_file}\")\n",
    "    print(f\"\\n{prediction_deltaF_file}\\nNumber of neurons in dataset: {len(array)}\")\n",
    "    estimated_spikes = []\n",
    "    for i in range(len(array)):\n",
    "        estimated_spikes.append(np.nansum(array[i]))\n",
    "    print(f\"For {prediction_deltaF_file[len(main_folder)+1:-38]} {int(sum(estimated_spikes))} spikes were predicted in total\")\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.hist(estimated_spikes, bins=50)\n",
    "    plt.xlabel(\"Number of total estimated spikes per neuron\")\n",
    "    plt.title(f'Histogram total number of spikes per neuron \\n {prediction_deltaF_file[len(main_folder)+1:-38]}')\n",
    "    plt.show()\n",
    "\n",
    "def plot_group_histograms(groups): ## plots histograms of total spikes per neuron for each group, possible to add a third group\n",
    "    from functions_data_transformation import get_file_name_list\n",
    "    for group in groups:\n",
    "        predictions_deltaF_files_group = get_file_name_list(folder_path = group, file_ending = \"predictions_deltaF.npy\") \n",
    "        group_arrays = []\n",
    "        estimated_spikes = []\n",
    "        for file in predictions_deltaF_files_group:\n",
    "            array = np.load(rf\"{file}\")\n",
    "            group_arrays.append(array)        \n",
    "        print(f\"{len(group_arrays)} files found for group {group[len(main_folder)+1:]}\")\n",
    "        group_array = np.concatenate(group_arrays, axis=0)\n",
    "        print(f\"{len(group_array)} total neurons in {group}\")\n",
    "        for i in range(len(group_array)):\n",
    "            estimated_spikes.append(np.nansum(group_array[i]))\n",
    "        print(f\"For group {group[len(main_folder)+1:]} {int(sum(estimated_spikes))} spikes were predicted in total\")\n",
    "        plt.figure(figsize=(5,5))\n",
    "        plt.hist(estimated_spikes, bins=50, density=True)\n",
    "        plt.ylim(0, 0.5)\n",
    "        plt.xlim(0,100) ## maybe make dynamic (get_max_spike_across_frames() could be useful or slight alteration), so it's the same for all groups\n",
    "        plt.title(f'Histogram estimated total number of spikes, {group[len(main_folder)+1:]}') ## y proprtion of neurons, x number of events, title estimated distribution total spike number\n",
    "        plt.xlabel(\"Number of estimated spikes\")\n",
    "        plt.show()\n",
    "        ## add titles axes labeling etc.\n",
    "\n",
    "def single_cell_peak_plotting(input_f, title): ## input f needs to be single cell\n",
    "    threshold = np.nanmedian(input_f)+np.nanstd(input_f)\n",
    "    peaks, _ = find_peaks(input_f, distance = 5, height = threshold)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(input_f)\n",
    "    plt.plot(peaks, input_f[peaks], \"x\")\n",
    "    plt.plot(np.full_like(input_f, threshold), \"--\",color = \"grey\") ## height in find_peaks\n",
    "    plt.plot(np.full_like(input_f, np.nanmean(input_f)), \"--\", color = 'r')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"frames\")\n",
    "    plt.show()\n",
    "\n",
    "    ## not sure how useful, maybe calculate peaks by AUC??? ##\n",
    "\n",
    "def visualization_process_single_cell(F_files, deltaF_files, predictions_deltaF_files, cells_plotted):\n",
    "    for file_number in range(len(predictions_deltaF_files)):\n",
    "        ## try with corrected trace too ??\n",
    "        prediction_array = np.load(rf\"{predictions_deltaF_files[file_number]}\", allow_pickle=True)\n",
    "        rawF_array = np.load(rf\"{F_files[file_number]}\", allow_pickle=True)\n",
    "        deltaF_array = np.load(rf\"{deltaF_files[file_number]}\", allow_pickle=True)\n",
    "        sample = np.random.randint(0,len(prediction_array), cells_plotted)\n",
    "        for cell in sample:\n",
    "            print(f\"raw fluorescence {predictions_deltaF_files[file_number][len(main_folder)+1:-38]}, cell {cell}\")\n",
    "            single_cell_peak_plotting(rawF_array[cell], f\"Raw fluorescence {predictions_deltaF_files[file_number][-45:-38]}, cell {cell}\")\n",
    "            print(f\"delta F {predictions_deltaF_files[file_number][len(main_folder)+1:-38]}, cell {cell}\")\n",
    "            single_cell_peak_plotting(deltaF_array[cell], f\"DeltaF {predictions_deltaF_files[file_number][-45:-38]}, cell {cell}\")\n",
    "            print(f\"cascade predictions {predictions_deltaF_files[file_number][len(main_folder)+1:-38]}, cell {cell}\")\n",
    "            single_cell_peak_plotting(prediction_array[cell], f\"Cascade predictions {predictions_deltaF_files[file_number][-45:-38]}, cell {cell}\")\n",
    "## maybe move those not used anymore to unused to other functions script\n",
    "\n",
    "def get_max_spike_across_frames(predictions_deltaF_file_list):\n",
    "    total_list=[]\n",
    "    for file in predictions_deltaF_file_list:\n",
    "        prediction_array = np.load(rf\"{file}\", allow_pickle=True)\n",
    "        sum_rows = np.nansum(prediction_array, axis=0)\n",
    "        total_list.extend(sum_rows)\n",
    "    return(max(total_list))\n",
    "## maybe move cause not related to plotting\n",
    "\n",
    "def plot_total_spikes_per_frame(prediction_deltaF_file, max_spikes_all_samples):\n",
    "    '''calculates the total spikes across whole culture at certain time point \\n the first input is a prediction_deltaF_file, the second input determines the scaling of the y axis and can be calculated by get_max_spikes_across_data()'''\n",
    "    prediction_array = np.load(rf\"{prediction_deltaF_file}\", allow_pickle=True)\n",
    "    sum_rows = np.nansum(prediction_array, axis=0)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(sum_rows, color = \"green\")\n",
    "    plt.title(f'Total spike probability summed across cells per frame')\n",
    "    plt.text(0.315, -0.115, f\"{prediction_deltaF_file[len(main_folder)+1:-38]}\", horizontalalignment='center', verticalalignment = \"center\", transform=plt.gca().transAxes)\n",
    "    plt.ylim(0,max_spikes_all_samples+10) ## make dynamic\n",
    "    plt.show\n",
    "\n",
    "def plot_average_spike_probability_per_frame(predictions_deltaF_file):\n",
    "    ''' plots average spike probability across all cells divided by total number of cells in dataset (regardless of active or not), standardizes output of plot_total_spikes_per_frame()'''\n",
    "    prediction_array = np.load(rf\"{predictions_deltaF_file}\", allow_pickle=True)\n",
    "    sum_rows = np.nansum(prediction_array, axis=0)\n",
    "    average = sum_rows/(len(prediction_array))\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(average, color = \"green\", label=\"average spike probability\")\n",
    "    ## actief_aandeel = (get_active_proportion_list(file)) ##used to also plot \"proportion\" line, not used anymore cause interpretation difficult\n",
    "    #plt.plot(actief_aandeel, color = \"magenta\", label = \"proportion of active cells\")\n",
    "    #plt.legend()\n",
    "    plt.title(f'Average spike probability across cells per frame')\n",
    "    plt.text(0.315, -0.115, f\"{predictions_deltaF_file[len(main_folder)+1:-38]}\", horizontalalignment='center', verticalalignment = \"center\", transform=plt.gca().transAxes)\n",
    "    plt.ylim(0,1)\n",
    "    plt.show\n",
    "\n",
    "## ROI image\n",
    "def getImg(ops):\n",
    "    \"\"\"Accesses suite2p ops file (itemized) and pulls out a composite image to map ROIs onto\"\"\"\n",
    "    Img = ops[\"meanImg\"] # Also \"max_proj\", \"meanImg\", \"meanImgE\"\n",
    "    mimg = Img # Use suite-2p source-code naming\n",
    "    mimg1 = np.percentile(mimg,1)\n",
    "    mimg99 = np.percentile(mimg,99)\n",
    "    mimg = (mimg - mimg1) / (mimg99 - mimg1)\n",
    "    mimg = np.maximum(0,np.minimum(1,mimg))\n",
    "    mimg *= 255\n",
    "    mimg = mimg.astype(np.uint8)\n",
    "    return mimg\n",
    "\n",
    "    #redefine locally suite2p.gui.utils import boundary\n",
    "def boundary(ypix,xpix):\n",
    "    \"\"\" returns pixels of mask that are on the exterior of the mask \"\"\"\n",
    "    ypix = np.expand_dims(ypix.flatten(),axis=1)\n",
    "    xpix = np.expand_dims(xpix.flatten(),axis=1)\n",
    "    npix = ypix.shape[0]\n",
    "    if npix>0:\n",
    "        msk = np.zeros((np.ptp(ypix)+6, np.ptp(xpix)+6), bool) \n",
    "        msk[ypix-ypix.min()+3, xpix-xpix.min()+3] = True\n",
    "        msk = binary_dilation(msk)\n",
    "        msk = binary_fill_holes(msk)\n",
    "        k = np.ones((3,3),dtype=int) # for 4-connected\n",
    "        k = np.zeros((3,3),dtype=int); k[1] = 1; k[:,1] = 1 # for 8-connected\n",
    "        out = binary_dilation(msk==0, k) & msk\n",
    "\n",
    "        yext, xext = np.nonzero(out)\n",
    "        yext, xext = yext+ypix.min()-3, xext+xpix.min()-3\n",
    "    else:\n",
    "        yext = np.zeros((0,))\n",
    "        xext = np.zeros((0,))\n",
    "    return yext, xext\n",
    "\n",
    "#gets neuronal indices\n",
    "def getStats(stat, frame_shape, output_df):\n",
    "    \"\"\"Accesses suite2p stats on ROIs and filters ROIs based on cascade spike probability being >= 1 into nid2idx and nid2idx_rejected (respectively)\"\"\"\n",
    "    MIN_PROB = 1.0 \n",
    "    pixel2neuron = np.full(frame_shape, fill_value=np.nan, dtype=float)\n",
    "    scatters = dict(x=[], y=[], color=[], text=[])\n",
    "    nid2idx = {}\n",
    "    nid2idx_rejected = {}\n",
    "    print(f\"Number of detected ROIs: {stat.shape[0]}\")\n",
    "    for n in range(stat.shape[0]):\n",
    "        estimated_spikes = output_df.iloc[n][\"EstimatedSpikes\"]\n",
    "\n",
    "        if estimated_spikes >= MIN_PROB:\n",
    "            nid2idx[n] = len(scatters[\"x\"]) # Assign new idx\n",
    "        else:\n",
    "            nid2idx_rejected[n] = len(scatters[\"x\"])\n",
    "\n",
    "        ypix = stat.iloc[n]['ypix'].flatten() - 1 #[~stat.iloc[n]['overlap']] - 1\n",
    "        xpix = stat.iloc[n]['xpix'].flatten() - 1 #[~stat.iloc[n]['overlap']] - 1\n",
    "\n",
    "        valid_idx = (xpix>=0) & (xpix < frame_shape[1]) & (ypix >=0) & (ypix < frame_shape[0])\n",
    "        ypix = ypix[valid_idx]\n",
    "        xpix = xpix[valid_idx]\n",
    "        yext, xext = boundary(ypix, xpix)\n",
    "        scatters['x'] += [xext]\n",
    "        scatters['y'] += [yext]\n",
    "        pixel2neuron[ypix, xpix] = n\n",
    "\n",
    "    return scatters, nid2idx, nid2idx_rejected, pixel2neuron\n",
    "\n",
    "\n",
    "def dispPlot(MaxImg, scatters, nid2idx, nid2idx_rejected,\n",
    "             pixel2neuron, F, Fneu, save_path, axs=None):\n",
    "             if axs is None:\n",
    "                fig = plt.figure(constrained_layout=True)\n",
    "                NUM_GRIDS=12\n",
    "                gs = fig.add_gridspec(NUM_GRIDS, 1)\n",
    "                ax1 = fig.add_subplot(gs[:NUM_GRIDS-2])\n",
    "                fig.set_size_inches(12,14)\n",
    "             else:\n",
    "                 ax1 = axs\n",
    "                 ax1.set_xlim(0, MaxImg.shape[0])\n",
    "                 ax1.set_ylim(MaxImg.shape[1], 0)\n",
    "             ax1.imshow(MaxImg, cmap='gist_gray')\n",
    "             ax1.tick_params(axis='both', which='both', bottom=False, top=False, \n",
    "                             labelbottom=False, left=False, right=False, labelleft=False)\n",
    "             print(\"Neurons count:\", len(nid2idx))\n",
    "            #  norm = matplotlib.colors.Normalize(vmin=0, vmax=1, clip=True) \n",
    "            #  mapper = cm.ScalarMappable(norm=norm, cmap=cm.gist_rainbow) \n",
    "\n",
    "             def plotDict(n2d2idx_dict, override_color = None):\n",
    "                 for neuron_id, idx in n2d2idx_dict.items():\n",
    "                     color = override_color if override_color else mapper.to_rgba(scatters['color'][idx])\n",
    "                            # print(f\"{idx}: {scatters['x']} - {scatters['y'][idx]}\")\n",
    "                            \n",
    "                     sc = ax1.scatter(scatters[\"x\"][idx], scatters['y'][idx], color = color, \n",
    "                                      marker='.', s=1)\n",
    "             plotDict(nid2idx, 'g')\n",
    "             plotDict(nid2idx_rejected, 'm')\n",
    "             ax1.set_title(f\"{len(nid2idx)} neurons used (green) out of {len(nid2idx)+len(nid2idx_rejected)} neurons detected (magenta - rejected)\") \n",
    "\n",
    "             plt.savefig(save_path)\n",
    "             plt.close(fig)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "suite2p",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
